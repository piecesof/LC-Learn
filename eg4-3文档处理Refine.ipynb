{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'该内容摘要如下：\\n\\n发表于2023年ICLR会议的论文《REACT：语言模型中推理与行动的协同》介绍了在大规模语言模型（LLM）中结合推理和行动的方法。该研究由普林斯顿大学计算机科学系及Google Research Brain团队共同完成，作者包括Shunyu Yao、Jeffrey Zhao等。\\n\\n摘要指出，在语言理解和交互式决策制定的各种任务中，语言模型在推理（例如：链式思维提示）与执行（例如：生成行动计划）方面的能力通常被分别研究。本文提出了一种新的方法REACT（Reasoning and Acting in Language Models），旨在以交错的方式让LLM生成推理痕迹和特定任务的行动，从而在两者之间实现更高的协同效应：推理痕迹帮助模型在生成、跟踪和更新行动计划以及处理复杂情境时更具灵活性。\\n\\n这种方法不仅增强了模型解决复杂问题的能力，还提高了其在实际应用中的实用性和灵活性。通过这种方式，REACT为构建更加智能且能够有效执行任务的语言模型提供了新的思路和方法。'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from functools import partial\n",
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate, format_document\n",
    "from langchain_core.output_parsers import  StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.document_loaders import ArxivLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# 加载arXiv上的论文ReAct: Synergizing Reasoning and Acting in Language Models\n",
    "loader = ArxivLoader(query = \"2210.03629\", load_max_docs = 1)\n",
    "docs = loader.load()\n",
    "\n",
    "# 把文本分割成500个字符为一组的片段\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500,\n",
    "    chunk_overlap = 50\n",
    ")\n",
    "chunks = text_splitter.split_documents(docs)\n",
    "\n",
    "llm = ChatOllama(model = 'qwen2.5')\n",
    "\n",
    "# 构建工具函数：将Document转换成字符串\n",
    "document_prompt = PromptTemplate.from_template('{page_content}')\n",
    "partial_format_document = partial(format_document, prompt = document_prompt)\n",
    "\n",
    "# 构建Context链：总结第一个文档并作为后续总结的上下文\n",
    "first_prompt = PromptTemplate.from_template('Summarize this content(用中文): \\n\\n {context}')\n",
    "context_chain = (\n",
    "        {'context': partial_format_document}\n",
    "        | first_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 构建Refine链：基于上下文（上一次的总结）和当前内容进一步总结\n",
    "refine_prompt = PromptTemplate.from_template(\n",
    "    \"Here's your first summary: {prev_response}.\"\n",
    "    \"Now add to it based on the following context: {context}\"\n",
    ")\n",
    "refine_chain = (\n",
    "    {\n",
    "        \"prev_response\": itemgetter(\"prev_response\"),\n",
    "        \"context\": lambda x: partial_format_document(x['doc']),\n",
    "    }\n",
    "    | refine_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 构建一个负责执行Refine循环的函数\n",
    "def refine_loop(docs):\n",
    "    summary = context_chain.invoke(docs[0])\n",
    "    for i, doc in enumerate(docs[1:]):\n",
    "        summary = refine_chain.invoke({'prev_response': summary, 'doc': doc})\n",
    "        return summary\n",
    "\n",
    "refine_loop(chunks[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Test1",
   "language": "python",
   "name": "test1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}